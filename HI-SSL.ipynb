{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from csl.obow.obow.datasets import show_data_for_obow\n",
    "from utils.data import Standard_DataLoader\n",
    "from copy import deepcopy\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBoW pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will be able to pretrain a ResNet18 encoder via the Self-Supervised Learning (SSL) approach \"[Online Bag of Visual Words](https://arxiv.org/pdf/2012.11552.pdf)\" (OBoW) on a dataset of manuscripts. The experimental results presented in [this work](https://www.sciencedirect.com/science/article/pii/S0306457322000097) show that SSL pretraining on such pretext task improves the performance of the encoder on the Handwriting Identification (HI) task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manuscript pages must be in JPEG or PNG format. At this stage, also unlabeled manuscripts (i.e., whose pages are not annotated with the scribe ID) can be used to increase the dataset size (which is useful for the success of the SSL method). Images should be arranged as the following example\n",
    "\n",
    "dataset\n",
    "- train\n",
    "    - Manuscript 1\n",
    "        - page 1\n",
    "        - page 2\n",
    "        - ...\n",
    "    - Manuscript 2\n",
    "        - page 3\n",
    "        - page 4\n",
    "        - ...    \n",
    "    - ...  \n",
    "- val\n",
    "    - Manuscript 1\n",
    "        - page 5\n",
    "        - page 6\n",
    "        - ...\n",
    "    - Manuscript 2\n",
    "        - page 7\n",
    "        - page 8\n",
    "        - ...    \n",
    "    - ... \n",
    "- test\n",
    "    - Manuscript 1\n",
    "        - page 9\n",
    "        - page 10\n",
    "        - ...\n",
    "    - Manuscript 2\n",
    "        - page 11\n",
    "        - page 12\n",
    "        - ...    \n",
    "    - ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './manuscript_dataset'       # Set here the dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output directory (logs, checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = './obow_results'       # Set here the output path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretext task configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for the parameter selection\n",
    "- [OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning](https://arxiv.org/pdf/2012.11552.pdf)\n",
    "- [OBoW GitHub repository](https://github.com/valeoai/obow)\n",
    "- [Self-supervised learning for medieval handwriting identification: A case study from the Vatican Apostolic Library](https://www.sciencedirect.com/science/article/pii/S0306457322000097)\n",
    "- [TORCHVISION.TRANSFORMS](https://pytorch.org/vision/0.9/transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base configuration file to modify as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csl/obow/config/Optional/Op.yaml', \"r\") as f:\n",
    "    exp_config = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config['model']['alpha'] = 0.99\n",
    "exp_config['model']['alpha_cosine'] = True\n",
    "exp_config['model']['feature_extractor_arch'] = 'resnet18'\n",
    "exp_config['model']['feature_extractor_opts']['global_pooling'] = True\n",
    "exp_config['model']['bow_levels'] = ['block3', 'block4']\n",
    "exp_config['model']['bow_extractor_opts']['inv_delta'] = 15\n",
    "exp_config['model']['bow_extractor_opts']['num_words'] = 8192\n",
    "exp_config['model']['bow_predictor_opts']['kappa'] = 8\n",
    "exp_config['model']['num_classes'] = 24       # Change here based on the number of classes of your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config['optim']['optim_type'] = 'sgd'\n",
    "exp_config['optim']['momentum'] = 0.9\n",
    "exp_config['optim']['weight_decay'] = 0.0001\n",
    "exp_config['optim']['nesterov'] = False\n",
    "exp_config['optim']['num_epochs'] = 100 \n",
    "exp_config['optim']['lr'] = 0.03 \n",
    "exp_config['optim']['end_lr'] = 0.00003\n",
    "exp_config['optim']['lr_schedule_type'] = 'cos_warmup'\n",
    "exp_config['optim']['warmup_epochs'] = 5\n",
    "exp_config['optim']['permanent'] = 100       # Save a permanent checkpoint every N epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config['data']['batch_size'] = 64       # Batch size\n",
    "exp_config['data']['cjitter'] = [[0.4, 1.3], 0.6, 0.6, 0.4]       # Color jitter parameters\n",
    "exp_config['data']['cjitter_p'] = 1       # Probability of using color jittering \n",
    "exp_config['data']['randaffine'] = [10, [0.2, 0.2], [1.3, 1.4], 1]       # Random affine transformation\n",
    "exp_config['data']['randpersp'] = [0.1, 0.2]       # Random perspective transformation\n",
    "exp_config['data']['gray_p'] = 0.2       # Probability of converting an image to grayscale\n",
    "exp_config['data']['gaussian_blur'] = [3, [0.1, 0.5]]       # Gaussian blur parameters\n",
    "exp_config['data']['target_img_size'] = 380       # Size of the image extracted from a given page x and fed to the teacher network\n",
    "exp_config['data']['num_img_crops'] = 2       # Number of random crops extracted from page x and fed to the student network\n",
    "exp_config['data']['image_crop_size'] = 270       # Size of the M random crops extracted from page x\n",
    "exp_config['data']['num_img_patches'] = 5       # Number of patches extracted from page x and fed to the student network\n",
    "exp_config['data']['img_patch_preresize'] = 256       # Size of the region of the page from which the K patches are extracted\n",
    "exp_config['data']['img_patch_size'] = 150       # Size of the K patches extracted from page x\n",
    "exp_config['data']['img_patch_jitter'] = 24       # Parameter that regulates the patch extraction stage\n",
    "exp_config['data']['rand_eras'] = [0.5, [0.02, 0.33], [0.3, 3.3], 0]       # Parameters of the random erasing transformation applied to crops\n",
    "exp_config['data']['rand_eras_patch'] = [0.7, [0.02, 0.1], [0.3, 3.3], 0]       # Parameters of the random erasing transformation applied to patches\n",
    "exp_config['data']['invert_p'] = 0.05       # Probability of inverting the colors of the RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_backup = deepcopy(exp_config['data'])\n",
    "\n",
    "del exp_config_backup['dataset_name']\n",
    "del exp_config_backup['batch_size']\n",
    "del exp_config_backup['epoch_size']\n",
    "\n",
    "dataset_train, dataset_val = show_data_for_obow(dataset_dir, **exp_config_backup)\n",
    "\n",
    "TTP = T.ToPILImage()\n",
    "\n",
    "print(f'Number of samples in training dataset: {len(dataset_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an image to visualize, together with the corresponding crops and patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = input(f'Enter an index in the range 0 - {len(dataset_train) - 1}: ')\n",
    "sample = dataset_train[int(idx)][0]\n",
    "\n",
    "target, crops, patches = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(TTP(target))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = len(crops)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, columns +1):\n",
    "    img = TTP(crops[i-1])\n",
    "    fig.add_subplot(1, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = len(patches)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, columns +1):\n",
    "    img = TTP(patches[i-1])\n",
    "    fig.add_subplot(1, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'OBoW_0'       # Change here to set the name of your experiment\n",
    "config_path = f'csl/obow/config/{exp_name}.yaml'\n",
    "\n",
    "with open(config_path, 'w') as outfile:\n",
    "    yaml.safe_dump(exp_config, outfile, default_flow_style = False, sort_keys = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run OBoW pre-training and save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python csl/obow/main_obow.py --config={exp_name} --workers=0 -p=100 --dst-dir={dest_dir} --data-dir={dataset_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the checkpoints into torchvision format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python csl/obow/main_obow.py --config={exp_name} --workers=0 -p=100 --dst-dir={dest_dir} --data-dir={dataset_dir} --convert-to-torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will be able to alternatively train from scratch a ResNet18 encoder or fine-tune it (after a preliminary pretraining either on the ImageNet dataset or via OboW) on a dataset of manuscript pages (each one annotated with the ID of the scribe who wrote it), with the aim of learning well-separated clusters of scribes (Handwriting Identification, HI).\n",
    "\n",
    "Such downstream task consists of training the network to minimize a triplet margin loss: hence, the HI task is configured as a **metric learning** problem, and **not** as a **classification** one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manuscript pages must be in JPEG or PNG format. At this stage, the **labeld** manuscripts only (i.e., whose pages are annotated with the scribe ID) must be used. Images should be arranged as the following example\n",
    "\n",
    "dataset\n",
    "- train\n",
    "    - Scribe A\n",
    "        - page 1\n",
    "        - page 2\n",
    "        - ...\n",
    "    - Scribe B\n",
    "        - page 3\n",
    "        - page 4\n",
    "        - ...    \n",
    "    - ...  \n",
    "- val\n",
    "    - Scribe A\n",
    "        - page 5\n",
    "        - page 6\n",
    "        - ...\n",
    "    - Scribe B\n",
    "        - page 7\n",
    "        - page 8\n",
    "        - ...    \n",
    "    - ... \n",
    "- test\n",
    "    - Scribe A\n",
    "        - page 9\n",
    "        - page 10\n",
    "        - ...\n",
    "    - Scribe B\n",
    "        - page 11\n",
    "        - page 12\n",
    "        - ...    \n",
    "    - ... \n",
    "    \n",
    "The test set can also include a different set of scribes than those used for fine-tuning the network, in order to assess the generalization power of the network. In this case, the test set will be structured as follows\n",
    "\n",
    "dataset\n",
    "- test\n",
    "    - Scribe α\n",
    "        - page 1\n",
    "        - page 2\n",
    "        - ...\n",
    "    - Scribe β\n",
    "        - page 11\n",
    "        - page 12\n",
    "        - ...    \n",
    "    - ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_HI = './scribe_dataset'       # Set here the dataset path for Handwriting Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream task configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for the parameter selection\n",
    "- [Self-supervised learning for medieval handwriting identification: A case study from the Vatican Apostolic Library](https://www.sciencedirect.com/science/article/pii/S0306457322000097)\n",
    "- [TORCH.OPTIM](https://pytorch.org/docs/stable/optim.html)\n",
    "- [LINEAR WARMUP COSINE ANNEALING](https://pytorch-lightning-bolts.readthedocs.io/en/stable/schedulers/warmup_cosine_annealing.html)\n",
    "- [Triplet Loss and Online Triplet Mining in TensorFlow](https://omoindrot.github.io/triplet-loss)\n",
    "- [TORCHVISION.TRANSFORMS](https://pytorch.org/vision/0.9/transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base configuration file to modify as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yaml', \"r\") as f:\n",
    "    exp_config_HI = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_HI['general']['test_id'] = 'HI_0'       # Change here to set the name of your experiment\n",
    "exp_config_HI['general']['seed'] = 1       # Global seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_HI['model']['num_classes'] = 23       # Number of classes (scribes) in the training set\n",
    "exp_config_HI['model']['emb_width'] = 1024       # Size of the page embeddings\n",
    "exp_config_HI['model']['pretraining'] = 'obow'       # Pretraining type (either \"obow\", \"imagenet\", or None)\n",
    "exp_config_HI['model']['mode'] = 'frozen'       # Set to \"frozen\" to freeze the backbone model weights and train the final linear layers only\n",
    "exp_config_HI['model']['cp_path'] = f'{dest_dir}/{exp_name}/checkpoints.pth.tar'       # If \"pretraining\" is set to \"obow\", change here to the corresponding model checkpoints path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_HI['optim']['optim_type'] = 'sgd'       # Optimizer type (either \"sgd\" or \"adam\")\n",
    "exp_config_HI['optim']['momentum'] = 0.9\n",
    "exp_config_HI['optim']['weight_decay'] = 0.0001\n",
    "exp_config_HI['optim']['nesterov'] = False\n",
    "exp_config_HI['optim']['num_epochs'] = 100       # Number of epochs\n",
    "exp_config_HI['optim']['lr'] = 0.6\n",
    "exp_config_HI['optim']['beta'] = [0.9, 0.999]\n",
    "exp_config_HI['optim']['end_lr'] = 0.0015\n",
    "exp_config_HI['optim']['lr_schedule_type'] = 'cos_warmup'       # Scheduler type (either \"cos_warmup\", \"step_lr\", \"exp\", or \"red_on_plateau\")\n",
    "exp_config_HI['optim']['step'] = 10\n",
    "exp_config_HI['optim']['gamma'] = 0.1\n",
    "exp_config_HI['optim']['patience'] = 10\n",
    "exp_config_HI['optim']['warmup_epochs'] = 10\n",
    "exp_config_HI['optim']['warmup_start_lr'] = 0.15\n",
    "exp_config_HI['optim']['loss']['margin'] = 0.2       # Margin parameter of the triplet margin loss\n",
    "exp_config_HI['optim']['loss']['squared'] = False        # Squared euclidean embedding distance (True) vs euclidean embedding distance (False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_HI['data']['batch_size'] = 256       # Batch size\n",
    "exp_config_HI['data']['transforms']['img_crop_size'] = 380       # Size of the image extracted from a given page x and fed to the network\n",
    "exp_config_HI['data']['transforms']['cjitter'] = {       # Color jitter parameters\n",
    "    'brightness': [0.4, 1.3],\n",
    "    'contrast': 0.6, \n",
    "    'saturation': 0.6,\n",
    "    'hue': 0.4}\n",
    "exp_config_HI['data']['transforms']['cjitter_p'] = 1       # Probability of using color jittering \n",
    "exp_config_HI['data']['transforms']['randaffine'] = {       # Random affine transformation\n",
    "    'degrees': [-10,10],\n",
    "    'translate': [0.2, 0.2],\n",
    "    'scale': [1.3, 1.4],\n",
    "    'shear': 1}\n",
    "exp_config_HI['data']['transforms']['randpersp'] = {       # Random perspective transformation\n",
    "    'distortion_scale': 0.1,\n",
    "    'p': 0.2}\n",
    "exp_config_HI['data']['transforms']['gray_p'] = 0.2       # Probability of converting an image to grayscale\n",
    "exp_config_HI['data']['transforms']['gaussian_blur'] = {       # Gaussian blur parameters\n",
    "    'kernel_size': 3,\n",
    "    'sigma': [0.1, 0.5]}\n",
    "exp_config_HI['data']['transforms']['rand_eras'] = {       # Parameters of the random erasing transformation\n",
    "    'p': 0.5,\n",
    "    'scale': [0.02, 0.33],\n",
    "    'ratio': [0.3, 3.3],\n",
    "    'value': 0}\n",
    "exp_config_HI['data']['transforms']['invert_p'] = 0.05       # Probability of inverting the colors of the RGB image\n",
    "exp_config_HI['data']['transforms']['n_test_crops'] = 10       # Number of crops extracted from page x and used to generate an average embedding of such page at test time\n",
    "exp_config_HI['data']['weighted_sampling'] = False       # Weighted sampling option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_HI['test']['ratio_train'] = 50       # Percentage of the training samples involved in the performance assessment\n",
    "exp_config_HI['test']['ratio_val'] = 100       # Percentage of the validation/test samples involved in the performance assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = Standard_DataLoader(f'{dataset_dir_HI}/train',\n",
    "                             exp_config_HI['data']['transforms'],\n",
    "                             batch_size = 8,\n",
    "                             weighted_sampling = False,\n",
    "                             phase = 'train',\n",
    "                             mean = [1e-9, 1e-9, 1e-9],\n",
    "                             std = [1, 1, 1],\n",
    "                             shuffle = False, \n",
    "                             amount = 0.3, \n",
    "                             selection = False)\n",
    "\n",
    "dataset_train_HI, _ = SD.load_data()\n",
    "\n",
    "TTP = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an image to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = input(f'Enter an index in the range 0 - {len(dataset_train_HI) - 1}: ')\n",
    "\n",
    "TTP(dataset_train_HI[int(idx)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path_HI = f'config/{exp_config_HI[\"general\"][\"test_id\"]}.yaml'\n",
    "\n",
    "with open(config_path_HI, 'w') as outfile:\n",
    "    yaml.safe_dump(exp_config_HI, outfile, default_flow_style = False, sort_keys = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the encoder on the HI task and save checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the process is launched, two folders are created:\n",
    "- **data**, where losses and plots are saved\n",
    "- **model/checkpoints**, where checkpoints are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py -dir=./ -td={dataset_dir_HI}/train -vd={dataset_dir_HI}/val -c={exp_config_HI['general']['test_id']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, you can assess the performance of the best model (according to the validation loss) on the test set with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_test.py -dir=./ -td={dataset_dir_HI}/train -vd={dataset_dir_HI}/test -c={exp_config_HI['general']['test_id']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
